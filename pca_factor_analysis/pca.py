import numpy as npimport pandas as pdimport matplotlib.pyplot as plt# ---------------------------# From Korea University Paper# ---------------------------df = pd.read_csv('lipset.csv', index_col=0)df.head()cor = df.corr()cor.head()U, S, V = np.linalg.svd(cor)SV.T.round(3)total_var = S.sum()cumsum_var = np.cumsum(S)pct_val_exp = cumsum_var/total_var*100plt.plot(pct_val_exp)plt.bar(x = range(len(cumsum_var)), height=cumsum_var)plt.show()plt.close()evac = V.Teval = S# Eigen vector i column vector if V at column ievac[:, 1]# Proof, A.dot(evac) = (eval)*(evac)cor.dot(evac[:, 1])/S[1]# select first 4 PCevac4 = evac[:,:4]eval4 = eval[:4]# calculate loading factorloading = evac4 * np.sqrt(eval4)load_df = pd.DataFrame(data = loading, index = df.columns,columns = ['PC1', 'PC2', 'PC3', 'PC4'])# score , data project on PCscore = np.linalg.inv(cor).dot(load_df)cor.shapedf.shapepc = load_df.T.dot(df.T)# ---------------------# PCA from Dr.Kanya# Multivariate analysis# ---------------------df = pd.read_csv('pca_data.csv', usecols=['v1','v2'])data = df.values# centered datacen_data = data - data.mean(axis=0)# cov matrix (auto centered, default sample covarience)cov_data = np.cov(cen_data, rowvar=False)# total sample variencedata.var(axis=0, ddof = 1) # ddof -> divided by N-ddof : sample variencecor_data = np.corrcoef(data, rowvar=False)eig_val, eig_vec = np.linalg.eig(cov_data)# proof A.eigen_vec = eigen_val.eigen_veccov_data.dot(eig_vec[:,0])/eig_val[0] == eig_vec[:,0]# change basis to PC1, PC2# use inv(eig_vec).dot(A.T)A_eig_basis = np.linalg.inv(eig_vec).dot(cen_data.T)# between PC, have zero covnp.cov(A_eig_basis)# loading factor = corrcoef of X, PCloading_x1_pc1 = np.corrcoef(cen_data[:,0], A_eig_basis.T[:,0])# --------# Exe.# --------C = np.array([[8,0,1],[0,8,3],[1,3,5]])eval, evac = np.linalg.eig(C)# 6.4df = pd.read_csv('ex6_4.csv')df.var()# 6.4.1 - Use Cov metrixcov_df = np.cov(df, rowvar=False)cov_eval, cov_evec = np.linalg.eigh(cov_df)# decending order by eigen valuesort_idx = cov_eval.argsort()[::-1]cov_eval_sort = cov_eval[sort_idx]cov_evec_sort = cov_evec[:,sort_idx]# Cutoff at 80% var explainedcov_eval_sort.cumsum()/cov_eval_sort.sum()*100# cut-off at 2nd Pc# 6.4.2 - Use CorrCoef metrixcor_df = df.corr()cor_eval, cor_evec = np.linalg.eig(cor_df)# decending order by eigen valuesort_idx = cor_eval.argsort()[::-1]cor_eval_sort = cor_eval[sort_idx]cor_evec_sort = cor_evec[:,sort_idx]# Cutoff at 80% var explainedcov_eval_sort.cumsum()/cov_eval_sort.sum()*100# also choose 2nd Pc# 6.5S_male = np.array([[5.192, 4.545, 6.522, 5.25],                   [4.545, 13.18, 6.67, 6.266],                   [6.522, 6.67, 28.67, 14.47],                   [5.25, 6.266, 14.47, 16.65]])m_eval, m_evac = np.linalg.eigh(S_male)sort_idx = m_eval.argsort()[::-1]m_eval_sort = m_eval[sort_idx]m_evac_sort = m_evac[:,sort_idx]m_eval_sort.cumsum()/m_eval_sort.sum()*100# -----------# Pearson PCA# -----------df = pd.read_csv('pearson_pca.csv', index_col = 0)cor_df = df.corr()cor_mat = cor_df.values.round(3)ei_va, ei_ve = np.linalg.eigh(cor_mat)# sort eigen_val, eigen vec by decendingei_va_de = ei_va[ei_va.argsort()[::-1]]ei_ve_de = ei_ve[:,ei_va.argsort()[::-1]]# factor loading of first 2 principalprin_va = ei_va_de[:2]prin_ve = ei_ve_de[:,:2]factor_loading = prin_ve*np.sqrt(prin_va)# rotation matrixtheta = np.radians(19)c, s = np.cos(theta), np.sin(theta)rotat = np.array([[c, -s],[s, c]])rotat_factor_loading = factor_loading.dot(rotat)# communality : how mush the varience of each features# was explained by F1, F2(rotat_factor_loading**2).sum(axis=1)# How mush each Fi explained to overall varience(rotat_factor_loading**2).sum(axis=0)/4# Reproduce correlation matrixre_cor_mat = rotat_factor_loading.dot(rotat_factor_loading.T).round(3)# residual cor_matres_cor_mat = cor_mat - re_cor_mat# -----------------------# Principa factor anaysis# -----------------------import pandas as pdimport numpy as npfrom statsmodels.multivariate import factor# datadf = pd.read_csv('pearson_pca.csv', index_col = 0)pfa = factor.Factor(df, n_factor=2)pfa_fit = pfa.fit()pfa_fit.plot_scree()pfa_fit.plot_loadings()pfa_fit.summary()pfa_fit.rotate('varimax')pfa_fit.summary()